# -*- coding: utf-8 -*-
"""proyectoCujilema.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wMKriBaKXgzLL_xZOr8AXVe6mCEva4tS
"""

import pandas as pd
import numpy as np
from sklearn import model_selection
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LassoCV #CV: Cross Validation / Validación Cruzada
from sklearn.linear_model import RidgeCV #CV: Cross Validation / Validación Cruzada
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_selection import RFE


# Función para cargar y preparar los datos
def load_and_prepare_data(url):
    # Cargar el dataset
    boston = pd.read_csv(url)
    boston.columns = boston.columns.str.upper()

    # Información básica del dataset
    print("El conjunto de datos Boston tiene", boston.shape[0], "FILAS y", boston.shape[1], "COLUMNAS")
    print("Boston info: -----------------------")
    print(boston.info())
    print("boston is null: -----------------------")
    print(boston.isnull().sum())
    print("boston describe: -----------------------")
    print(boston.describe())
    print("boston group by: -----------------------")
    print(boston.groupby('MEDV').size())

    return boston

# Función para dividir los datos en entrenamiento y prueba
def split_data(data, test_size=0.2, random_state=1):
    train_data, test_data = model_selection.train_test_split(data, test_size=test_size, random_state=random_state)
    train_data = train_data.reset_index(drop=True)
    test_data = test_data.reset_index(drop=True)

    print("Shape of the original boston data: ", data.shape)
    print("Shape of the boston train data = ", train_data.shape)
    print("Shape of the boston test data = ", test_data.shape)

    return train_data, test_data

# Función para crear y mostrar un heatmap de correlación
def plot_correlation_heatmap(data, title, figsize=(12, 8)):
    corr_matrix = data.corr()
    plt.figure(figsize=figsize)
    sns.heatmap(
        data=corr_matrix,
        annot=True,
        fmt=".2f",
        cmap="coolwarm",
        vmin=-1,
        vmax=1,
        linewidths=0.5,
        linecolor="black"
    )
    plt.title(title, fontsize=16)
    plt.xticks(rotation=45, ha="right")
    plt.tight_layout()
    plt.show()

# Función para calcular el VIF
def calculate_vif(data, features):
    vif_data = pd.DataFrame()
    vif_data["Variable"] = features
    vif_data["VIF"] = [variance_inflation_factor(data[features].values, i) for i in range(len(features))]
    return vif_data

# Función para entrenar y evaluar el modelo
def train_and_evaluate(name_modelo, train_features, train_labels, test_features, test_labels, alphas=np.logspace(-4, 1, 50)):
    # model_result = LassoCV(alphas=alphas, cv=5, random_state=1) # Crear el modelo de Lasso con Cross Validation
    # model_result = RidgeCV(alphas=alphas, cv=5) # Crear el modelo de Ridge con Cross Validation
    # model_result = LinearRegression() # Crear el modelo de Regresión Lineal
    # model_result = DecisionTreeRegressor(random_state=1) # Crear el modelo de Árbol de Decisión * este modelo se utilizará



    if name_modelo == 'Ridge':
      model_result = RidgeCV(alphas=alphas, cv=5)
    elif name_modelo == 'Lasso':
      model_result = LassoCV(alphas=alphas, cv=5, random_state=1)
    elif name_modelo == 'LinearRegression':
      model_result = LinearRegression()
    elif name_modelo == 'DecisionTreeRegressor':
      model_result = DecisionTreeRegressor(random_state=1)

    # Nombre del modelo:
    print(f'\n *************************** MODELO - {name_modelo} **************************')

    # Aplicar validación cruzada adicional para evaluar el modelo
    scores = cross_val_score(model_result, train_features, train_labels, cv=5, scoring='neg_mean_squared_error')
    mse_scores = -scores

    # Imprimir los resultados de la validación cruzada
    print("MSE en cada fold:", mse_scores)
    print("MSE promedio (Validación Cruzada):", mse_scores.mean())
    print("Desviación estándar del MSE (Validación Cruzada):", mse_scores.std())

    # Entrenar el modelo final con todos los datos de entrenamiento
    model_result.fit(train_features, train_labels)

    # Hacer predicciones en el conjunto de prueba
    predictions = model_result.predict(test_features)

    # Crear un DataFrame con las predicciones
    predictions_df = pd.DataFrame(predictions, columns=['lr_prediction'])
    test_predictions = pd.concat([test_labels.reset_index(drop=True), predictions_df], axis=1)
    print(test_predictions.head(5))

    # Interpretar los coeficientes del modelo Lasso

    # Interpretar los coeficientes de todos los modelos excepto en Decision Tree porque ese atributo no existe
    if any(substring in name_modelo for substring in ['Ridge', 'Lasso', 'linear']):
      print("Intercepto (b0):", model_result.intercept_)
      print("Coeficientes (b1, b2, b3, b4):", model_result.coef_)

    # Gráfico de dispersión entre valores reales y predichos
    plt.scatter(test_labels, predictions)
    plt.xlabel('Actual Labels')
    plt.ylabel('Predicted Labels')
    plt.title(f'Predicción de Precios de Casas - {name_modelo}')
    z = np.polyfit(test_labels.values.flatten(), predictions, 1)
    p = np.poly1d(z)
    plt.plot(test_labels, p(test_labels), color='red')
    plt.show()

    # Evaluar el modelo con métricas
    mae = mean_absolute_error(test_labels, predictions)
    mse = mean_squared_error(test_labels, predictions)
    rmse = np.sqrt(mse)
    r2 = r2_score(test_labels, predictions)

    # MAE MSE RMSE R2
    # Métricas de evaluación utilizadas en modelos de regresión para medir que tan bien las predicciones se ajustan a los valores reales
    print(f'*************** MÉTRICAS DE EVALUACIÓN ***************')
    print("MAE:", mae)
    print("MSE:", mse)
    print("RMSE:", rmse)
    print("R2:", r2)

    # return model_result **** borrar

    return {
        'modelo': name_modelo,
        'mae': mae,
        'mse': mse,
        'rmse': rmse,
        'r2': r2,
        'modelo_entrenado': model_result
    }


def select_features_by_rfe(X, y, n_features_to_select=4):
    """
    Selecciona variables usando Recursive Feature Elimination (RFE).

    Parámetros:
    - X: DataFrame con las variables independientes.
    - y: Series con la variable dependiente.
    - n_features_to_select: Número de variables a seleccionar (por defecto 4).

    Retorna:
    - selected_features: Lista de variables seleccionadas.
    """
    # Crear el modelo base (puedes usar LinearRegression, RandomForest, etc.)
    # model = LinearRegression()
    model = RandomForestRegressor(random_state=1)

    # Crear el selector RFE
    rfe = RFE(model, n_features_to_select=n_features_to_select)
    rfe.fit(X, y)

    # Seleccionar las variables
    selected_features = X.columns[rfe.support_].tolist()

    return selected_features


# -------------------- Ejecución principal --------------------

# Cargar y preparar los datos
boston = load_and_prepare_data("https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv")

# Dividir los datos en entrenamiento y prueba
boston_train, boston_test = split_data(boston)

# Selección de características
boston_features =   ['RM', 'ZN', 'PTRATIO', 'LSTAT'] # ['RM', 'ZN', 'LSTAT'] #
boston_labels = ['MEDV']

print('BOSTON DATASET')
print("Features: " + str(boston_features))
print("Labels: " + str(boston_labels))

# Definir características y etiquetas
boston_train_features = boston_train[boston_features]
boston_train_labels = boston_train[boston_labels]
boston_test_features = boston_test[boston_features]
boston_test_labels = boston_test[boston_labels]

# Heatmap de correlación para todas las variables
plot_correlation_heatmap(boston_train, "Matriz de Correlación - Boston Housing Dataset")

# Heatmap de correlación para las variables independientes
plot_correlation_heatmap(boston_train_features, "Matriz de Correlación (Variables Independientes)", figsize=(10, 8))

# Calcular el VIF para las variables independientes
vif_data = calculate_vif(boston_train, boston_features)
print(vif_data)


#nuevo codigo: 10-03-2025
# Convertir la columna boston_train_labels a un array unidimensional boston_train_labels_array
boston_train_labels = boston_train_labels.values.ravel()

# Entrenar y evaluar el modelo
# Entrenar y evaluar todos los modelos
#model_train_eval = train_and_evaluate('Ridge', boston_train_features, boston_train_labels, boston_test_features, boston_test_labels)
#model_train_eval = train_and_evaluate('Lasso', boston_train_features, boston_train_labels, boston_test_features, boston_test_labels)
#model_train_eval = train_and_evaluate('LinearRegression', boston_train_features, boston_train_labels, boston_test_features, boston_test_labels)
#model_train_eval = train_and_evaluate('DecisionTreeRegressor', boston_train_features, boston_train_labels, boston_test_features, boston_test_labels)

# Lista de modelos a evaluar ---------------------------------------------
modelos = ['Ridge', 'Lasso', 'LinearRegression', 'DecisionTreeRegressor']

# Diccionario para almacenar los resultados de cada modelo
resultados = []

# Entrenar y evaluar cada modelo
for modelo in modelos:
    resultado = train_and_evaluate(modelo, boston_train_features, boston_train_labels, boston_test_features, boston_test_labels)
    resultados.append(resultado)

# Comparación de los modelos y selección del mejor
mejor_modelo = max(resultados, key=lambda x: x['r2'])  # Se elige el que tenga el R² más alto

# Mostrar resumen de los modelos evaluados
print("\nComparación de modelos:")
df_resultados = pd.DataFrame(resultados).drop(columns=['modelo_entrenado'])
print(df_resultados)

# Mostrar el mejor modelo
print(f"\nEl mejor modelo según el R² es: {mejor_modelo['modelo']} con un R² de {mejor_modelo['r2']:.4f}")

# Bloque final: Seleccionar las mejores variables ------------------------------------------------------------------
X = boston_train[['RM', 'ZN', 'PTRATIO', 'LSTAT', 'INDUS', 'NOX', 'AGE', 'DIS', 'RAD', 'TAX', 'CRIM', 'B', 'CHAS']]
y = boston_train['MEDV']
selected_features = select_features_by_rfe(X, y, n_features_to_select=4) # boston_train[boston_features] # X #boston_train_features
print("Variables seleccionadas por RFE:", selected_features)

